# go-website-url-crawler
A webcrawler/scraper written in go that crawls and creates a list of all internal urls and their response in a CSV

#Running the crawler
Once the program has been compiled using `go build` you can run the application in terminal/dos. When running you must provide a -url flag to define the address of the website you want to be crawled.
